% !TEX root = ../thesis-example.tex
%
\chapter{Reject Options}
\label{sec:options}

\section{Two Classes}
\label{twoclasses}
To make our way towards optimal rejects for multi class classification, we start of small by looking at a general two class classifier $f$ that divides the space via a decision boundary. 
\begin{align}
f: \mathbb{R}^n \to \{1,2\}
\end{align} 
Let $r$ be a measure of confidence that a point is part of its respective class, e.g. distance to the decision boundary. If $r(\bar{x})$ is large it means that $\bar{x}$ is likely in the class it was assigned to.

\begin{figure}[!htbp]
\centering
\caption{Example of two classes separated by a decision boundary. You can see falsely classified points near the boundary which we would like to reject.}
\label{decBound}
\begin{tikzpicture}
	\node {\svg{\textwidth}{2classDecBoundary}};
	\draw[ultra thick] (0.235,-1.25) -- (0.235,1.6);
\end{tikzpicture}
\end{figure}

We look for a threshold $\theta$ that defines for a given point $\bar{x}$ whether it is rejected or not:
 \begin{align}
 r(\bar{x}) < \theta : \bar{x} \  rejected 
 \end{align}

\subsection{Optimal Reject Threshold $\theta$}
\label{optimalt}
In order to find an optimal threshold we need to decide how to evaluate it. Optimally only wrongly classified data points are rejected (now referred to as true rejects). But generally there will be rejected, although correctly classified, points (false rejects). 
A given labeled data set $X = \{\bar{x}_1,...,\bar{x}_n\}$ (by $y(\bar{x}) \mapsto \{1,2\}$) is divided into the two sets $L$ and $E$ by applying $f$ as a classifier with:
\begin{align} 
L&=\{\forall \bar{x} \in X \ | \ f(\bar{x}) = y(\bar{x})\} : \text{correctly classified points} \\
E&=\{\forall \bar{x} \in X \ | \ f(\bar{x}) \neq y(\bar{x})\} : \text{incorrectly classified points} 
\end{align}
And by applying our reject strategy with the threshold $\theta$, $X$ is divided into $A_\theta$ and $R_\theta$ with:
\begin{align} 
A_\theta&=\{\forall \bar{x} \in X \ | \ r(\bar{x}) \geq \theta \} : \text{accepted points} \\
R_\theta&=\{\forall \bar{x} \in X \ | \ r(\bar{x}) < \theta\} : \text{rejected points} 
\end{align}
The set $T_\theta$ contains all true rejects and $F_\theta$ all false rejects.
\begin{align} 
T_\theta &= R_\theta \cap E \\ 
F_\theta &= R_\theta \cap L
\end{align}
Naturally, we want $|T_\theta|$ to be large and $|F_\theta|$ to be small. Since these two goals often contradict each other, e.g. more true rejects most times bring more false ones (see figure \ref{incTaF}), in general there is no single optimal choice of $\theta$. Still there is a set of values that we consider optimal. As shown above each $\theta$ corresponds to a tuple $(|T_\theta|,|F_\theta|)$. $\theta$ is optimal if
\begin{align}
\nexists \theta^{'} : |F_{\theta^{'}}|\leq|F_\theta|, |T_{\theta^{'}}|\geq|T_\theta|
\end{align}
and at least one inequality holds, thus being Pareto optimal.

\begin{figure}[!htbp]
\centering
\caption{In this example we can see the corresponding true and false rejects if $r(\bar{x})$ is chosen as a threshold for each $\bar{x} \in X$. $r(\bar{x})$ is increasing from the bottom left corner to the upper right. As we can see, the number of false and true rejects are monotonically increasing with a more strict threshold.}
\label{incTaF}
	\begin{tikzpicture}
		\node {\svg{12cm}{increasingTrueandFalse}};
	\end{tikzpicture}
\end{figure}

\subsection{Finding Reasonable Values for $\theta$}
\label{findt}
Now that we know how to evaluate our thresholds we still need to know where to look for them. Obviously $\theta$ needs to be in the range of $r$ so
\begin{align}
\Theta := \{\theta \in \mathbb{R} \ | \ \operatorname*{min}_{\bar{x}} r(\bar{x})\ < \theta < \operatorname*{max}_{\bar{x}} r(\bar{x})\}
\end{align}
is the set of possible thresholds. Because this set is infinitely large we need to reduce its size. We recognize that it is sufficient to only consider the discreet set $\Theta := \{r(\bar{x}) | \forall \bar{x} \in X\}$ of the values of $r$. This is a feasible set of possible thresholds. It can be refined by looking again at our criteria for an optimal $\theta$. Let \footnote{For the sake of simplicity we assume that the data set $X$ is ordered according to the measure $r$.}
\begin{align}
\bar{r} = (\bar{r}(1),...,\bar{r}(n)) \ | \ \bar{r}(i)= r(\bar{x}_i) \forall \bar{x}_i \in X, \bar{r}(i) < \bar{r}(i+1) \forall i \in \{1,...,n-1\}
\end{align}
be the vector of thresholds in $\Theta$ sorted by the measure of confidence in ascending order. Consider $\bar{r}(i)$ as threshold. We now consider different cases:
\begin{itemize}
	\item $\bar{x}_{i-1} \in E$: $\bar{r}(i-1)$ cannot be a better choice since it would result in one less true reject.
	\item $\bar{x}_{i-1} \in L$: $\bar{r}(i-1)$ is a better threshold since it gives one less false reject.
	\item $\bar{x}_i \in E$: $ \bar{r}(i+1)$ is a better threshold since it adds a true reject.
	\item $\bar{x}_i \in L$: $ \bar{r}(i+1)$ cannot be a better threshold since it adds a false reject.
\end{itemize} 
In conclusion this means that it is sufficient to consider only points at the beginning of groups of correctly classified points, giving us
\begin{align}
\Theta := \{r(\bar{x}_i) \ | \ \bar{x}_i \in L, \ \bar{x}_{i-1} \in E\}
\end{align}
as an easily computed set of thresholds to consider to be optimal (see figures \ref{possibleThresholds} and \ref{paretoFront}.)

\begin{figure}[!htbp]
\centering
\caption{This figure shows the thresholds from before (see figure \ref{incTaF}). The green marked points correspond to threshold we consider optimal.}
\label{paretoFront}
	\begin{tikzpicture}
		\node {\svg{12cm}{paretoFront}};
	\end{tikzpicture}
\end{figure}

\begin{figure}[!htbp]
\centering
\caption{This is an example of classified points sorted by a measure of confidence. You can see that $r(\bar{x}_2)$ and $r(\bar{x}_7)$ are the only sensible thresholds. Choosing $r(\bar{x}_8)$ instead of $r(\bar{x}_7)$ would only add a false reject and choosing $r(\bar{x}_6)$ over $r(\bar{x}_7)$ would result in one less true reject.}
\label{possibleThresholds}
\begin{tikzpicture}
	\node[draw=none] at (0.6,1.2) {$r(\bar{x}) \rightarrow$};
	\draw[style=thick] (0,0) rectangle (10,1);
	\draw[fill=white] (0.5,0.5) circle (0.35) node {$\bm{\bar{x}_1}$};
	\draw[fill=myBlue,text=white,draw=myBlue] (1.5,0.5) circle (0.35) node {$\bm{\bar{x}_2}$};
	\draw[fill=myBlue,text=white,draw=myBlue] (2.5,0.5) circle (0.35) node {$\bm{\bar{x}_3}$};
	\draw[fill=white] (3.5,0.5) circle (0.35) node {$\bm{\bar{x}_4}$};
	\draw[fill=white] (4.5,0.5) circle (0.35) node {$\bm{\bar{x}_5}$};
	\draw[fill=white] (5.5,0.5) circle (0.35) node {$\bm{\bar{x}_6}$};
	\draw[fill=myBlue,text=white,draw=myBlue] (6.5,0.5) circle (0.35) node {$\bm{\bar{x}_7}$};
	\draw[fill=myBlue,text=white,draw=myBlue] (7.5,0.5) circle (0.35) node {$\bm{\bar{x}_8}$};
	\draw[fill=myBlue,text=white,draw=myBlue] (8.5,0.5) circle (0.35) node {$\bm{\bar{x}_9}$};
	\draw[fill=white] (9.5,0.5) circle (0.35) node {$\bm{\bar{x}_{10}}$};
	
	\draw[ultra thick] (1,1) -- (1,0) node [label=below:{$\theta_1$}] {};
	\draw[ultra thick] (6,1) -- (6,0) node [label=below:{$\theta_2$}] {};
	
	\draw[fill=white] (0.5,-2) circle (0.35);
		\node[draw=none] at (2.9,-2) {falsely classified points};
	\draw[fill=myBlue,draw=myBlue] (0.5,-3) circle (0.35);
		\node[draw=none] at (3.1,-3) {correctly classified points};
\end{tikzpicture}
\end{figure}


\section{Multi Class Classification}
Let us now expand the problem to a classifier for $N$ classes.
By using a one vs all strategy, we get $N$ binary classifiers $f_k$ like in chapter \ref{twoclasses} and an according measure of confidence $r_k$. Points are now classified in the class where $f_k$ is maximal among all classes. This gives us a multi class classifier $f$ with
\begin{align}
 f: \mathbb{R}^n &\to \{1,...,N\} \\
   \bar{x} &\mapsto \operatorname*{arg\,max}_k f_k(\bar{x}) 
\end{align}

\subsection{Global Reject}
To adapt our reject strategy from before, we search for a threshold $\theta$ and reject according to our measures of confidence:
\begin{align}
\operatorname*{max}_k r_k(\bar{x}) < \theta \ : \ \bar{x} \ \text{rejected}
\end{align}
We look again to choose $\theta$ so that it meets our requirements for an optimal threshold (see chapter \ref{optimalt}). This strategy comes with the problem that it relies on all measures $r_k$ to be scaled the same way. While there might be a workaround for this, e.g. using probabilities as scale, a global reject is still imprecise when the internal structures of the classes differ a lot(see figure \ref{classStructure}). A reasonable threshold for a class with most points and also most classification errors near the decision plane is probably not well suited for a class with a larger variance in its set of data points. This leads to the idea of having individual thresholds for each class.

\begin{figure}[!htbp]
\centering
\caption{In this two-class classification example one class (blue circles) has few errors near the decision boundary and the other (red triangles) multiple further away. A global reject optimal for the first class would result in a lot of unrejected errors in class 2. Conversely an optimal global reject for class 2 would result in many false rejects in class 1.}
\label{classStructure}
\begin{tikzpicture}
	\node {\svg{\textwidth}{classStructure}};
	\draw[ultra thick] (-0.5,-0.9) -- (-0.5,1.3);
\end{tikzpicture}
\end{figure}

\subsection{Local Reject}
\label{localreject}
To account for differences in class structure we define local reject thresholds $\theta_k$. A point is rejected if
\begin{align}
r_k(\bar{x}) < \theta_k \ | \ \forall \bar{x} \  \text{where} \ f(\bar{x}) = k
\end{align}
This gives us an N-dimensional threshold vector $\bar{\theta} = (\theta_1,...,\theta_N)$. Each $\theta_k$ regulates the reject practice only in their respective class.

\subsection{Optimal Local Reject}
For each threshold $\theta_k$ the same criteria apply to determine if it is optimal as for a global threshold (see chapter \ref{optimalt}). With the difference that we look at each class individually. So the true and false rejects are now given by
\begin{align} 
T_{\theta_k}^k &= R_{\theta_k}^k \cap E^k \\ 
F_{\theta_k}^k &= R_{\theta_k}^k \cap L^k, \\
\forall \theta_k \in \Theta_k &:= \{r_k(\bar{x}_i) \ | \ \bar{x}_i \in L^k, \ \bar{x}_{i-1} \in E^k\}, \ \forall k \in \{1,...N\}
\end{align}
where $R_{\theta_k}^k$ is the set of rejected points in class $k$ given the threshold $\theta_k$, $E^k$ the set of falsely classified points in class $k$ and $L^k$ the set of correctly classified points in $k$. We conclude that the threshold vector $\bar{\theta}=(\theta_1,...,\theta_N)$ is optimal if each $\theta_k$ is optimal. Conversely an optimal $\theta_k$ is not necessarily a component of an optimal vector $\bar{\theta}$.


\subsection{Computation by Brute Force}
To now find the optimal local reject vectors $\bar{\theta}$ with a brute force approach we need to consider every combination of thresholds in the sets $\Theta_k$. Let
\begin{align}
\mathbb{P} = \left\{\bar{\theta} = \left(\theta_1,...,\theta_N\right) \in \Theta_1 \times ... \times \Theta_N \right\}
\end{align}
be the set of all choices from the sets of optimal thresholds of each class. Algorithm \ref{bruteForce} describes in pseudo code how to find all optimal $\bar{\theta}$.

\begin{algorithm}[!htbp]
 \KwData{$\mathbb{P}$}
 \KwResult{set of optimal local reject vectors $\Theta_{opt}$}
 initialization\;
 array $opt$ where $opt(n)$ is the maximum number of true rejects with n false ones initialzied with $0$ in every item \;
 array $theta$ where $theta(n)$ is the optimal threshold vector with n false rejects \; 
 \ForEach{$\bar{\theta} \in \mathbb{P}$}{
 	$F :=$ amount of false rejects for $\bar{\theta}$ \;
 	$T :=$ amount of true rejects for $\bar{\theta}$ \;
 	\If{$opt(F)<T$}{
 		$opt(F):=T$ \;
 		$theta(F)=\bar{\theta}$ \;
 	}
 }
 \KwRet{theta}
 \BlankLine \BlankLine
 \caption{Computing optimal local reject options by brute force.}
 \label{bruteForce}
\end{algorithm}

\subsection{Computation by Dynamic Programming}
\label{dp}
Computation by brute force scales exponentially with the number of classes and is therefore not a feasible solution for large data sets with lots of classes. However our problem is equivalent to a multiple choice knapsack problem \cite{Sin:1979} where thresholds within a class correspond to items, false rejects correspond to costs, and true rejects correspond to their value. Thus a dynamic programming scheme is available that allows computation in polynomial time.
Let


\begin{align}
opt(n,j,i) = \max_{\bar{\theta}}
\begin{Bmatrix}
	 & \left|F_{\bar{\theta}}\right| \leq  & n \\
  	\left|T_{\bar{\theta}}\right| \ s.t. & \theta_l \in & \Theta_l \forall l < j \\
  	 & \theta_j \in & \left\{\bar{\theta}_j(0),...,\bar{\theta}_j(i)\right\} \\
  	 & \theta_l \in & \bar{\theta}_l(0) \forall l > j
\end{Bmatrix}
\end{align}

with 
\begin{align}
	n &\in \{0,...,|L|\} \\
	j &\in \{1,...,N\} \\
	i &\in \{0,...,\left|\Theta_j\right|-1\} \\
	\bar{\theta}_k &= (\bar{\theta}(0),...,\bar{\theta}(n_k-1)) \ | \ \bar{\theta}(i) \in \Theta_k, \ \bar{\theta}(i) < \bar{\theta}(i+1) \forall i \in \{0,...,n_k-2\}, n_k:=\left|\Theta_k\right|
\end{align}
be the maximum number of true rejects with $n$ false rejects while considering all thresholds in classes before class $j$ and the first $i$ thresholds in class $j$. All $\bar{\theta}$ corresponding to $opt(n,N,\left|\Theta_N\right|-1) \forall n<\left|L\right|$ fulfill our criteria for an optimal threshold vector. \\
This results in the Bellmann equation \ref{DP} \cite{Bel:1957} to efficiently compute $opt$:

\begin{subnumcases}{opt(n,j,i) = \label{DP}}
\text{if} \ n=0 : &$ \ \sum_{k=1}^{N} \left|T_{\bar{\theta}_k(0)}^k\right|$ \label{DPcase1}\\
\text{if} \ n>0\text{,}\ j=0 : &$ \ \sum_{k=1}^{N} \left|T_{\bar{\theta}_k(0)}^k\right|$ \label{DPcase2}\\
\text{if} \ n>0\text{,}\ j>0\text{,}\ i=0 : &$ opt\left(n,j-1,\left|\Theta_{j-1}\right|-1\right)$ \label{DPcase3}\\
\text{if} \ 0<n<\left|F_{\bar{\theta}_j(i)}^j\right|\text{,}\ j>0 :  &$ opt\left(n,j,i-1\right)$ \label{DPcase4}\\
\text{if} \ n \geq \left|F_{\bar{\theta}_j(i)}^j\right|>0\text{,}\ j>0 :  &$ max\Bigg\{opt\left(n,j,i-1\right),$ \notag \\
&$\ opt\left(n-\left|F_{\bar{\theta}_j(i)}^j\right|,j-1,\left|\bar{\theta}_{j-1}\right|-1\right)+$ \notag\\
&$\ \left|T_{\bar{\theta}_j(i)}^j\right|-\left|T_{\bar{\theta}_j(0)}^j\right|\Bigg\}$ \label{DPcase5}
\end{subnumcases} 



Each case is explained as follows:
\begin{itemize}
\item Case \ref{DPcase1}: $n=0$ means that no false rejects are allowed so the first threshold (index 0) in each class is chosen. The resulting amount of true rejects is summed up over all classes.
\item Case \ref{DPcase2}: $j=0$ means that no class is under consideration for a threshold. So we stay with the first threshold in each class (see above). 
\item Case \ref{DPcase3}: $i=0$ means that no threshold is under consideration in class $j$. So we look in the previous class with the strictest threshold possible.
\item Case \ref{DPcase4}: The chosen threshold $i$ in class $j$ exceeds the allowed amount of false rejects, so the next less strict threshold is considered.
\item Case \ref{DPcase5}: Here the $i$th threshold in $j$ is a possible threshold but it is not clear whether it is optimal. We consider both cases. If it is not the optimal threshold, we take the next less strict one. If it is optimal, we continue our search in the previous class but with $|F_{\bar{\theta}_j(i)}^j|$ less allowed false rejects in consequence to choosing this threshold. The other consequence is that this threshold results in a number of gained true rejects compared to the least strict threshold and this gain is added.
\end{itemize}

Algorithm \ref{DPpseudo} shows this method in pseudo code. We use three nested loops over $n$, $j$ and $i$. This results in a processing time of $\mathbb{O}(|L| \cdot N \cdot \max_k \left|\Theta_k\right|)$. The optimal thresholds can be retrieved from the matrix $opt$ via backtracing.
Note that this is equal in effort to the previous method in \cite{Fis:2015} but the worst case is far less likely to occur here since it would mean that there are no groups of classification errors. Every grouping of falsely classified points means less computation time than the previous method.

\begin{algorithm}[!htbp]
	\KwData{sets of thresholds $\Theta_k$}
	\KwResult{matrix $opt(n,j)$}
	\For{$j=0,...,N$}{
		$opt(0,j) := \sum_{k=1}^{N} \left|T_{\bar{\theta}_k(0)}^k\right|$ \;
	}
	\For{$n=0,...,|L|$}{
		$opt(n,0) := \sum_{k=1}^{N} \left|T_{\bar{\theta}_k(0)}^k\right|$ \;
	} 
	\For{$n=0,...,|L|$}{
		\For{$j=0,...,N$}{
			$opt(n,j) = opt(n,j-1)$\;
			\ForEach{$i \in \{1,...,n\} \ | \  \left|F_{\bar{\theta}_j(i)}^j\right| < n$}{
				$n'=n-\left|F_{\bar{\theta}_j(i)}^j\right|$\;
				$g=\left|T_{\bar{\theta}_j(i)}^j\right|-\left|T_{\bar{\theta}_j(0)}^j\right|$\;
				$h=opt(n',j-1)+g$\;
				\If{$h>opt(n,j)$}{
					$opt(n,j)=h$\;
				}
			}
		}
	}
\KwRet{$opt$}
\BlankLine \BlankLine
\caption{Computing optimal local reject options by dynamic programming.}
\label{DPpseudo}
\end{algorithm}
\newpage

\subsection{Greedy Computation}
\label{greedyAlg}
Computation by dynamic programming gives us an optimal local reject option, but it still might be infeasible in some cases since it "scales quadratically with the number of data" \cite{Fis:2015}. Hence we are looking for a greedy approximation with linear running time. For this approach we define
\begin{align}
 	\bigtriangleup T_{\bar{\theta}_k(j)}^k = \left|T_{\bar{\theta}_k(j)}^k\right|-\left|T_{\bar{\theta}_k(j-1)}^k\right| \\
	\bigtriangleup F_{\bar{\theta}_k(j)}^k = \left|F_{\bar{\theta}_k(j)}^k\right|-\left|F_{\bar{\theta}_k(j-1)}^k\right|
\end{align}
as the amount of true and false rejects gained by a threshold compared to its predecessor and
\begin{align}
g = \bigtriangleup T_{\bar{\theta}_k}^k - \bigtriangleup F_{\bar{\theta}_k}^k
\end{align}
as the local gain. The greedy approach lies within choosing the thresholds with the best local gain. Initially all thresholds are set to the most tolerant in each class. Looking at the next strict one in each class we pick the one with the highest local gain until the strictest possible thresholds are reached. The pair of true and false rejects $\left(\left|T_{\bar{\theta}_k}^k\right|,\left|F_{\bar{\theta}_k}^k\right|\right)$ is saved in each step if it is an improvement to an existing solution. Algorithm \ref{greedy} details this procedure in pseudo code. 

\begin{algorithm}[!htbp]
 \KwData{sets of thresholds $\Theta_k$}
 \KwResult{set of optimal local reject vectors $\Theta_{opt}$}
 initialization\;
 array $opt$ where $opt(n)$ is the maximum number of true rejects with n false ones \;
 array $theta$ where $theta(n)$ is the optimal threshold vector with n false rejects \; 
 $\bar{\theta} = \left\{\bar{\theta}_0(0),...,\bar{\theta}_N(0)\right\}$ \; 
 $F :=$ amount of false rejects for $\bar{\theta}$ \;
 $T :=$ amount of true rejects for $\bar{\theta}$ \;
 \While{a more strict threshold in at least one class exists}{
 	\ForEach{$\theta_k(j) \in \bar{\theta}$}{
 		\eIf{$j+1<\left|\Theta_k\right|$}{
 			$g(k) = \bigtriangleup T_{\bar{\theta}_k(j+1)}^k - \bigtriangleup F_{\bar{\theta}_k(j+1)}^k$ \;
 		}{
 			$g(k) = -\infty$ \;
 		}	
 	}
 	$\hat{k}=\operatorname*{arg\,max}_k g(k)$ \;
 	set threshold $\theta_{\hat{k}}(j)$ in $\bar{\theta}$ to $\theta_{\hat{k}}(j+1)$ \;
 	$T = T +  \bigtriangleup T_{\bar{\theta}_{\hat{k}}(j+1)}^{\hat{k}}$ \;
 	$F = F +  \bigtriangleup F_{\bar{\theta}_{\hat{k}}(j+1)}^{\hat{k}}$ \;
 	\If{$opt(F)<T$}{
 	 	$opt(F):=T$ \;
 	 	$theta(F)=\bar{\theta}$ \;
 	}
 }
 \KwRet{theta}
 \BlankLine \BlankLine
 \caption{Computing optimal local reject options by greedy evaluation.}
 \label{greedy}
\end{algorithm}

\section{Evaluation}
In this section we evaluate the described methods. We try to confirm the optimality of the dynamic programming method by comparing its result to the brute force algorithm. Additionally we will compare the run time of both algorithms. Furthermore we want to find out how close the greedy approach is to being optimal.

\subsection{Data Sets}
For our evaluation we use randomly generated data sets. Using a normal distribution we get random samples of points divided into two classes, above and below $0$. We now introduce further normal distributions at random locations to get cluster of falsely classified points (see figure \ref{dataset}).

\begin{figure}[!htbp]
\centering
\caption{Example of a small 2-classes generated data set with one group of falsely classified points in each class.}
\label{dataset}
\begin{tikzpicture}
	\node {\svg{\textwidth}{rndDataSet}};
	\begin{axis}[hide axis,
	  no markers, domain=0:10, samples=200,
	  axis lines*=left, xlabel=$x$, ylabel=$y$,
	  every axis y label/.style={at=(current axis.above origin),anchor=south},
	  every axis x label/.style={at=(current axis.right of origin),anchor=west},
	  height=2.5cm, width=6cm,
	  xtick={4,6.5}, ytick=\empty,
	  enlargelimits=false, clip=false, axis on top,
	  grid = major,
	  at={(-400,-260)}
	  ]
	  \addplot [thick,myBlue!50!black] {gauss(1.35,0.3)};
	  \addplot [thick,myBlue!50!black] {gauss(8.95,0.3)};
	\end{axis}
	
\end{tikzpicture}
\end{figure}

To simulate multi class data sets we use multivariate normal distributions to generate random points for data sets with four classes (2D) and with eight classes (3D). The points are separated into the respective class by the coordinate axis (one quadrant corresponds to a class).

\subsection{Evaluation Measures}
In regards to our definition of an optimal threshold (see chapter \ref{optimalt}) we use the true and false rejects of each threshold considered to be optimal by the respective method. To further see the behavior of the reject options we introduce a measure of quality of the classification in a second evaluation method. Based on \cite{Nad:2010} we compare the ratio of accepted points to all points $ \left( \frac{\left|A_{\bar{\Theta}}\right|}{|X|}\right) $ as reject accuracy to the ratio of correctly classified points to all accepted points $ \left(\frac{\left|L \cap A_{\bar{\Theta}}\right|}{\left|A_{\bar{\Theta}}\right|}\right) $ as classification accuracy.


\subsection{DP vs Brute Force}
\label{DPvsBF}
Since we formally did not proof that the Bellman equation (see chapter \ref{dp}) finds every optimal reject option we compare its result to the outcome of the brute force method. We can see in figure \ref{dpEvaPareto} that the results match for nine different generated data sets. Although this is, of course, no proof we conclude for now that the dynamic programming algorithm finds optimal thresholds.

\begin{figure}[!htbp]
\centering
\caption{This figure shows the true and false rejects for the thresholds considered optimal by dynamic programming(green circles) and by brute force(red crosses) on different randomly generated data sets. We can see that the results coincide in each case. }
\label{dpEvaPareto}
\begin{tikzpicture}
	\node {\svg{\textwidth}{dpComp}};
\end{tikzpicture}
\end{figure}

When comparing the running time of both methods we can see that for multiple classes (eight) we observe the expected result. The brute force method's running time grows exponentially (see figure \ref{runTime}).

\begin{figure}[!htbp]
\centering
\caption{Here we can see the running time in seconds of the brute force (red) compared to the dynamic programming algorithm (green). A small amount of points lets the brute force method be competitive due to constant factors in the implementation. However the time increases exponentially with larger data sets.}
\label{runTime}
\begin{tikzpicture}
	\node {\svg{\textwidth}{runTime}};
\end{tikzpicture}
\end{figure}

\subsection{DP vs Greedy}
\label{DPvsGR}
We now compare the results of the greedy strategy (see chapter \ref{greedyAlg}) to the optimum. If the results are nearly accurate it is a feasible solution for big data sets since its running time is linear. We can observe in figure \ref{greedyEvaPareto} that the results of the greedy computation are mostly close to being optimal and that outliers are rare and not extreme. Using ARCs (see figure \ref{greedyEvaARC}) we can observe that the greedy reject options lead to a very similar quality of classification as the ideal ones.

\begin{figure}[!htbp]
\centering
\caption{Comparison of the thresholds computed greedily (red crosses) and the optimal ones computed by dynamic programming (green circles) on randomly generated data sets. We can see that the greedy strategy is close to optimal and sometimes falls off slightly if a lot of points are rejected. There are no noticeable differences when the number of classes is increased.}
\label{greedyEvaPareto}
\begin{tikzpicture}
	\node {\svg{\textwidth}{greedyComp}};
\end{tikzpicture}
\end{figure}


\begin{figure}[!htbp]
\centering
\caption{ARCs for data sets classified with optimal rejects (green curve) and with greedy rejects (red dashed curve). This supports our observation from the previous test (see figure \ref{greedyEvaPareto}) in that the greedy approach can compete with the optimal solutions.}
\label{greedyEvaARC}
\begin{tikzpicture}
	\node {\svg{\textwidth}{greedyARC}};
\end{tikzpicture}
\end{figure}
